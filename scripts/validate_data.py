#!/usr/bin/env python3
"""
å­¦ä¼šãƒžã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã¨å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
"""

import csv
import sys
import io
from collections import Counter, defaultdict
from datetime import datetime

# UTF-8å‡ºåŠ›è¨­å®š
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def load_csv(filepath):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(filepath, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        return list(reader)

def check_duplicates(data):
    """é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    # å­¦ä¼šIDé‡è¤‡ãƒã‚§ãƒƒã‚¯
    ids = [row['å­¦ä¼šID'] for row in data]
    id_counts = Counter(ids)
    for id_val, count in id_counts.items():
        if count > 1:
            issues.append(f"âŒ å­¦ä¼šIDé‡è¤‡: {id_val} ({count}ä»¶)")
    
    # æ­£å¼åç§°é‡è¤‡ãƒã‚§ãƒƒã‚¯
    names = [row['æ­£å¼åç§°'] for row in data]
    name_counts = Counter(names)
    for name, count in name_counts.items():
        if count > 1:
            issues.append(f"âš ï¸  æ­£å¼åç§°é‡è¤‡: {name} ({count}ä»¶)")
    
    return issues

def check_required_fields(data):
    """å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯"""
    issues = []
    required = ['å­¦ä¼šID', 'æ­£å¼åç§°', 'ã‚«ãƒ†ã‚´ãƒª', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹']
    
    for i, row in enumerate(data, 2):  # 2è¡Œç›®ã‹ã‚‰ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ãï¼‰
        for field in required:
            if not row.get(field):
                issues.append(f"âŒ è¡Œ{i}: {field}ãŒç©ºã§ã™")
    
    return issues

def check_categories(data):
    """ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆã¨æ¤œè¨¼"""
    stats = {}
    valid_categories = {'åŸºæœ¬é ˜åŸŸ', 'ã‚µãƒ–ã‚¹ãƒš', 'ãã®ä»–'}
    issues = []
    
    categories = [row['ã‚«ãƒ†ã‚´ãƒª'] for row in data]
    cat_counts = Counter(categories)
    
    for cat, count in cat_counts.items():
        if cat not in valid_categories:
            issues.append(f"âš ï¸  ä¸æ˜Žãªã‚«ãƒ†ã‚´ãƒª: {cat}")
        stats[cat] = count
    
    return stats, issues

def check_parent_references(data):
    """è¦ªå­¦ä¼šå‚ç…§ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
    issues = []
    id_set = {row['å­¦ä¼šID'] for row in data}
    
    for row in data:
        if row['è¦ªå­¦ä¼šID']:
            # è¤‡æ•°ã®è¦ªå­¦ä¼šIDå¯¾å¿œ
            parent_ids = row['è¦ªå­¦ä¼šID'].split('/')
            for parent_id in parent_ids:
                if parent_id and parent_id not in id_set:
                    issues.append(f"âš ï¸  {row['å­¦ä¼šID']}: å­˜åœ¨ã—ãªã„è¦ªå­¦ä¼šIDå‚ç…§: {parent_id}")
    
    return issues

def check_data_quality(data):
    """ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
    quality_scores = []
    
    for row in data:
        score = 100
        filled_fields = sum(1 for v in row.values() if v)
        total_fields = len(row)
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å……å¡«çŽ‡
        fill_rate = filled_fields / total_fields
        score = int(fill_rate * 100)
        
        # é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æœ‰ç„¡
        if row.get('å°‚é–€åŒ»æ©Ÿæ§‹èªå®š') == 'TRUE':
            score += 10
        if row.get('åŽšåŠ´çœåºƒå‘Šå¯èƒ½') == 'TRUE':
            score += 10
        if row.get('ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ'):
            score += 5
        if row.get('ä¼šå“¡æ•°ï¼ˆåŒ»å¸«ï¼‰'):
            score += 5
        
        quality_scores.append(min(score, 100))
    
    avg_score = sum(quality_scores) / len(quality_scores)
    high_quality = sum(1 for s in quality_scores if s >= 80)
    
    return {
        'average_score': avg_score,
        'high_quality_count': high_quality,
        'total_count': len(quality_scores)
    }

def generate_report(filepath):
    """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    print("=" * 60)
    print("å­¦ä¼šãƒžã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    print(f"æ¤œè¨¼æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = load_csv(filepath)
    print(f"âœ… ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(data)}")
    print()
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    print("ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯ã€‘")
    dup_issues = check_duplicates(data)
    if dup_issues:
        for issue in dup_issues:
            print(f"  {issue}")
    else:
        print("  âœ… é‡è¤‡ãªã—")
    print()
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
    print("ã€å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ã€‘")
    req_issues = check_required_fields(data)
    if req_issues:
        for issue in req_issues[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
            print(f"  {issue}")
        if len(req_issues) > 5:
            print(f"  ... ä»–{len(req_issues)-5}ä»¶")
    else:
        print("  âœ… ã™ã¹ã¦å…¥åŠ›æ¸ˆã¿")
    print()
    
    # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
    print("ã€ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã€‘")
    cat_stats, cat_issues = check_categories(data)
    for cat, count in sorted(cat_stats.items()):
        print(f"  {cat}: {count}ä»¶")
    if cat_issues:
        for issue in cat_issues:
            print(f"  {issue}")
    print()
    
    # è¦ªå­¦ä¼šå‚ç…§ãƒã‚§ãƒƒã‚¯
    print("ã€è¦ªå­¦ä¼šå‚ç…§ãƒã‚§ãƒƒã‚¯ã€‘")
    ref_issues = check_parent_references(data)
    if ref_issues:
        for issue in ref_issues[:5]:
            print(f"  {issue}")
        if len(ref_issues) > 5:
            print(f"  ... ä»–{len(ref_issues)-5}ä»¶")
    else:
        print("  âœ… ã™ã¹ã¦æ­£å¸¸")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢
    print("ã€ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢ã€‘")
    quality = check_data_quality(data)
    print(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {quality['average_score']:.1f}/100")
    print(f"  é«˜å“è³ªãƒ¬ã‚³ãƒ¼ãƒ‰: {quality['high_quality_count']}/{quality['total_count']}ä»¶")
    print()
    
    # ç·åˆè©•ä¾¡
    print("ã€ç·åˆè©•ä¾¡ã€‘")
    critical_issues = len([i for i in dup_issues + req_issues if i.startswith('âŒ')])
    warnings = len([i for i in dup_issues + req_issues + cat_issues + ref_issues if i.startswith('âš ï¸')])
    
    if critical_issues == 0 and warnings == 0:
        print("  ðŸŽ‰ å„ªç§€: ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’ãƒ‘ã‚¹")
    elif critical_issues == 0:
        print(f"  âœ… è‰¯å¥½: è­¦å‘Š{warnings}ä»¶ï¼ˆè‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ãªã—ï¼‰")
    else:
        print(f"  âš ï¸  è¦æ”¹å–„: ã‚¨ãƒ©ãƒ¼{critical_issues}ä»¶ã€è­¦å‘Š{warnings}ä»¶")
    
    print("=" * 60)
    
    return critical_issues == 0

if __name__ == "__main__":
    filepath = "../data/societies_master.csv"
    if len(sys.argv) > 1:
        filepath = sys.argv[1]
    
    success = generate_report(filepath)
    sys.exit(0 if success else 1)